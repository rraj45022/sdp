{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c649c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9028946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>Alkphos</th>\n",
       "      <th>Sgpt</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>A/G Ratio</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender    TB   DB   Alkphos   Sgpt   Sgot   TP   ALB  A/G Ratio  \\\n",
       "0  65.0  Female   0.7  0.1     187.0   16.0   18.0  6.8   3.3       0.90   \n",
       "1  62.0    Male  10.9  5.5     699.0   64.0  100.0  7.5   3.2       0.74   \n",
       "2  62.0    Male   7.3  4.1     490.0   60.0   68.0  7.0   3.3       0.89   \n",
       "3  58.0    Male   1.0  0.4     182.0   14.0   20.0  6.8   3.4       1.00   \n",
       "4  72.0    Male   3.9  2.0     195.0   27.0   59.0  7.3   2.4       0.40   \n",
       "\n",
       "   Result  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b56c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>Alkphos</th>\n",
       "      <th>Sgpt</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>A/G Ratio</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30686</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30687</th>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>482.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30688</th>\n",
       "      <td>54.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30689</th>\n",
       "      <td>48.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30690</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>253.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender   TB   DB   Alkphos   Sgpt   Sgot   TP   ALB  A/G Ratio  \\\n",
       "30686  50.0    Male  2.2  1.0     610.0   17.0   28.0  7.3   2.6       0.55   \n",
       "30687  55.0    Male  2.9  1.3     482.0   22.0   34.0  7.0   2.4       0.50   \n",
       "30688  54.0    Male  6.8  3.0     542.0  116.0   66.0  6.4   3.1       0.90   \n",
       "30689  48.0  Female  1.9  1.0     231.0   16.0   55.0  4.3   1.6       0.60   \n",
       "30690  30.0    Male  3.1  1.6     253.0   80.0  406.0  6.8   3.9       1.30   \n",
       "\n",
       "       Result  \n",
       "30686       1  \n",
       "30687       1  \n",
       "30688       1  \n",
       "30689       1  \n",
       "30690       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6642709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Result'].replace(2, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1de30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>Alkphos</th>\n",
       "      <th>Sgpt</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>A/G Ratio</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30689.000000</td>\n",
       "      <td>30043.000000</td>\n",
       "      <td>30130.000000</td>\n",
       "      <td>29895.000000</td>\n",
       "      <td>30153.000000</td>\n",
       "      <td>30229.000000</td>\n",
       "      <td>30228.000000</td>\n",
       "      <td>30197.000000</td>\n",
       "      <td>30132.000000</td>\n",
       "      <td>30691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.107205</td>\n",
       "      <td>3.370319</td>\n",
       "      <td>1.528042</td>\n",
       "      <td>289.075364</td>\n",
       "      <td>81.488641</td>\n",
       "      <td>111.469979</td>\n",
       "      <td>6.480237</td>\n",
       "      <td>3.130142</td>\n",
       "      <td>0.943467</td>\n",
       "      <td>0.714118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.981043</td>\n",
       "      <td>6.255522</td>\n",
       "      <td>2.869592</td>\n",
       "      <td>238.537589</td>\n",
       "      <td>182.158850</td>\n",
       "      <td>280.851078</td>\n",
       "      <td>1.081980</td>\n",
       "      <td>0.792281</td>\n",
       "      <td>0.323164</td>\n",
       "      <td>0.451841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>2110.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age            TB            DB       Alkphos          Sgpt  \\\n",
       "count  30689.000000  30043.000000  30130.000000  29895.000000  30153.000000   \n",
       "mean      44.107205      3.370319      1.528042    289.075364     81.488641   \n",
       "std       15.981043      6.255522      2.869592    238.537589    182.158850   \n",
       "min        4.000000      0.400000      0.100000     63.000000     10.000000   \n",
       "25%       32.000000      0.800000      0.200000    175.000000     23.000000   \n",
       "50%       45.000000      1.000000      0.300000    209.000000     35.000000   \n",
       "75%       55.000000      2.700000      1.300000    298.000000     62.000000   \n",
       "max       90.000000     75.000000     19.700000   2110.000000   2000.000000   \n",
       "\n",
       "               Sgot            TP           ALB     A/G Ratio        Result  \n",
       "count  30229.000000  30228.000000  30197.000000  30132.000000  30691.000000  \n",
       "mean     111.469979      6.480237      3.130142      0.943467      0.714118  \n",
       "std      280.851078      1.081980      0.792281      0.323164      0.451841  \n",
       "min       10.000000      2.700000      0.900000      0.300000      0.000000  \n",
       "25%       26.000000      5.800000      2.600000      0.700000      0.000000  \n",
       "50%       42.000000      6.600000      3.100000      0.900000      1.000000  \n",
       "75%       88.000000      7.200000      3.800000      1.100000      1.000000  \n",
       "max     4929.000000      9.600000      5.500000      2.800000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4b5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30691 entries, 0 to 30690\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Age        30689 non-null  float64\n",
      " 1   Gender     29789 non-null  object \n",
      " 2   TB         30043 non-null  float64\n",
      " 3   DB         30130 non-null  float64\n",
      " 4    Alkphos   29895 non-null  float64\n",
      " 5    Sgpt      30153 non-null  float64\n",
      " 6   Sgot       30229 non-null  float64\n",
      " 7   TP         30228 non-null  float64\n",
      " 8    ALB       30197 non-null  float64\n",
      " 9   A/G Ratio  30132 non-null  float64\n",
      " 10  Result     30691 non-null  int64  \n",
      "dtypes: float64(9), int64(1), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa337e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(15,15), xrot=-45,bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3bb5b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>Alkphos</th>\n",
       "      <th>Sgpt</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>A/G Ratio</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender    TB   DB   Alkphos   Sgpt   Sgot   TP   ALB  A/G Ratio  \\\n",
       "0  65.0       0   0.7  0.1     187.0   16.0   18.0  6.8   3.3       0.90   \n",
       "1  62.0       1  10.9  5.5     699.0   64.0  100.0  7.5   3.2       0.74   \n",
       "2  62.0       1   7.3  4.1     490.0   60.0   68.0  7.0   3.3       0.89   \n",
       "3  58.0       1   1.0  0.4     182.0   14.0   20.0  6.8   3.4       1.00   \n",
       "4  72.0       1   3.9  2.0     195.0   27.0   59.0  7.3   2.4       0.40   \n",
       "\n",
       "   Result  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66409f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age            2\n",
       "Gender         0\n",
       "TB           648\n",
       "DB           561\n",
       " Alkphos     796\n",
       " Sgpt        538\n",
       "Sgot         462\n",
       "TP           463\n",
       " ALB         494\n",
       "A/G Ratio    559\n",
       "Result         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a839a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate(inplace=True)  # Linear interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ad7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Gender', 'TB', 'DB', 'Alkphos', 'Sgpt', 'Sgot', 'TP', 'ALB', 'A/G Ratio', 'Result']\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to remove non-printable characters\n",
    "df.rename(columns=lambda x: x.strip().replace('\\xa0', ''), inplace=True)\n",
    "\n",
    "# Now check the column names\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66949dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "features_to_normalize = ['Age', 'TB', 'DB', 'Alkphos', 'Sgpt', 'Sgot', 'TP', 'ALB', 'A/G Ratio']\n",
    "\n",
    "# Min-Max scaling\n",
    "df[features_to_normalize] = scaler.fit_transform(df[features_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38b422e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>Alkphos</th>\n",
       "      <th>Sgpt</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>A/G Ratio</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.709302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.674419</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140751</td>\n",
       "      <td>0.275510</td>\n",
       "      <td>0.310699</td>\n",
       "      <td>0.027136</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674419</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092493</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.208598</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.011791</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.627907</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.058134</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.790698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046917</td>\n",
       "      <td>0.096939</td>\n",
       "      <td>0.064485</td>\n",
       "      <td>0.008543</td>\n",
       "      <td>0.009961</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender        TB        DB   Alkphos      Sgpt      Sgot  \\\n",
       "0  0.709302       0  0.004021  0.000000  0.060576  0.003015  0.001626   \n",
       "1  0.674419       1  0.140751  0.275510  0.310699  0.027136  0.018296   \n",
       "2  0.674419       1  0.092493  0.204082  0.208598  0.025126  0.011791   \n",
       "3  0.627907       1  0.008043  0.015306  0.058134  0.002010  0.002033   \n",
       "4  0.790698       1  0.046917  0.096939  0.064485  0.008543  0.009961   \n",
       "\n",
       "         TP       ALB  A/G Ratio  Result  \n",
       "0  0.594203  0.521739      0.240       1  \n",
       "1  0.695652  0.500000      0.176       1  \n",
       "2  0.623188  0.521739      0.236       1  \n",
       "3  0.594203  0.543478      0.280       1  \n",
       "4  0.666667  0.326087      0.040       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c28c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Result\n",
    "X=df.drop('Result', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82e2bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b1c35a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00163693, 0.00297745, 0.10380612, 0.0909234 , 0.266383  ,\n",
       "       0.1550719 , 0.18649076, 0.03871416, 0.04915218, 0.09796757])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Calculate mutual information for classification task\n",
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "011acf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>Alkphos</th>\n",
       "      <th>Sgpt</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>A/G Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>-0.006060</td>\n",
       "      <td>-0.003615</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>-0.003875</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>-0.015332</td>\n",
       "      <td>-0.020270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.021505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>0.023711</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TB</th>\n",
       "      <td>-0.006060</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865872</td>\n",
       "      <td>0.194282</td>\n",
       "      <td>0.195815</td>\n",
       "      <td>0.233436</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>-0.216879</td>\n",
       "      <td>-0.203838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DB</th>\n",
       "      <td>-0.003615</td>\n",
       "      <td>0.023711</td>\n",
       "      <td>0.865872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224436</td>\n",
       "      <td>0.218511</td>\n",
       "      <td>0.254019</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>-0.224929</td>\n",
       "      <td>-0.200011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alkphos</th>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.194282</td>\n",
       "      <td>0.224436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113158</td>\n",
       "      <td>0.144308</td>\n",
       "      <td>-0.023215</td>\n",
       "      <td>-0.155356</td>\n",
       "      <td>-0.224276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sgpt</th>\n",
       "      <td>-0.003875</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>0.195815</td>\n",
       "      <td>0.218511</td>\n",
       "      <td>0.113158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786264</td>\n",
       "      <td>-0.041855</td>\n",
       "      <td>-0.024258</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sgot</th>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.233436</td>\n",
       "      <td>0.254019</td>\n",
       "      <td>0.144308</td>\n",
       "      <td>0.786264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027571</td>\n",
       "      <td>-0.079011</td>\n",
       "      <td>-0.059871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>-0.023215</td>\n",
       "      <td>-0.041855</td>\n",
       "      <td>-0.027571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767084</td>\n",
       "      <td>0.223465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>-0.015332</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>-0.216879</td>\n",
       "      <td>-0.224929</td>\n",
       "      <td>-0.155356</td>\n",
       "      <td>-0.024258</td>\n",
       "      <td>-0.079011</td>\n",
       "      <td>0.767084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A/G Ratio</th>\n",
       "      <td>-0.020270</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-0.203838</td>\n",
       "      <td>-0.200011</td>\n",
       "      <td>-0.224276</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.059871</td>\n",
       "      <td>0.223465</td>\n",
       "      <td>0.669673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age    Gender        TB        DB   Alkphos      Sgpt  \\\n",
       "Age        1.000000  0.021505 -0.006060 -0.003615  0.001069 -0.003875   \n",
       "Gender     0.021505  1.000000  0.021749  0.023711  0.012632  0.017066   \n",
       "TB        -0.006060  0.021749  1.000000  0.865872  0.194282  0.195815   \n",
       "DB        -0.003615  0.023711  0.865872  1.000000  0.224436  0.218511   \n",
       "Alkphos    0.001069  0.012632  0.194282  0.224436  1.000000  0.113158   \n",
       "Sgpt      -0.003875  0.017066  0.195815  0.218511  0.113158  1.000000   \n",
       "Sgot      -0.000411  0.015511  0.233436  0.254019  0.144308  0.786264   \n",
       "TP        -0.006999  0.001724  0.002126  0.009129 -0.023215 -0.041855   \n",
       "ALB       -0.015332  0.001666 -0.216879 -0.224929 -0.155356 -0.024258   \n",
       "A/G Ratio -0.020270  0.000702 -0.203838 -0.200011 -0.224276  0.000638   \n",
       "\n",
       "               Sgot        TP       ALB  A/G Ratio  \n",
       "Age       -0.000411 -0.006999 -0.015332  -0.020270  \n",
       "Gender     0.015511  0.001724  0.001666   0.000702  \n",
       "TB         0.233436  0.002126 -0.216879  -0.203838  \n",
       "DB         0.254019  0.009129 -0.224929  -0.200011  \n",
       "Alkphos    0.144308 -0.023215 -0.155356  -0.224276  \n",
       "Sgpt       0.786264 -0.041855 -0.024258   0.000638  \n",
       "Sgot       1.000000 -0.027571 -0.079011  -0.059871  \n",
       "TP        -0.027571  1.000000  0.767084   0.223465  \n",
       "ALB       -0.079011  0.767084  1.000000   0.669673  \n",
       "A/G Ratio -0.059871  0.223465  0.669673   1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = X_train.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ac978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs of features with correlation > 0.5:\n",
      "('TB', 'DB')\n",
      "('Sgpt', 'Sgot')\n",
      "('TP', 'ALB')\n",
      "('ALB', 'A/G Ratio')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming correlation_matrix is the correlation matrix of your features\n",
    "# You can compute it using X_train.corr() if X_train is a DataFrame\n",
    "\n",
    "# Get the names of the features\n",
    "feature_names = correlation_matrix.columns\n",
    "\n",
    "# Initialize a list to store pairs of highly correlated features\n",
    "highly_correlated_pairs = []\n",
    "\n",
    "# Iterate through the correlation matrix\n",
    "for i in range(len(feature_names)):\n",
    "    for j in range(i + 1, len(feature_names)):\n",
    "        # Check if the absolute correlation value is greater than 0.5\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.5:\n",
    "            # Add the pair of feature names to the list\n",
    "            highly_correlated_pairs.append((feature_names[i], feature_names[j]))\n",
    "\n",
    "# Print the highly correlated pairs\n",
    "print(\"Pairs of features with correlation > 0.5:\")\n",
    "for pair in highly_correlated_pairs:\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50c543bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05317194,  0.        ,  0.1004174 ,  0.11626103,  0.07896977,\n",
       "        0.06070599,  0.06281631,  0.04350071,  0.02604581,  0.03076139])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skrebate import ReliefF\n",
    "\n",
    "# Create ReliefF instance and fit it to the data\n",
    "relief = ReliefF(n_neighbors=10)\n",
    "relief.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Get ReliefF scores\n",
    "relief_scores = relief.feature_importances_\n",
    "relief_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7eaddada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['TB', 'DB', 'Alkphos', 'Sgpt', 'Sgot'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Assuming X_train is your training data and y_train is the corresponding labels\n",
    "\n",
    "# Initialize the model you want to use for feature selection\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Initialize RFE with the model and the number of desired features to select\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)  # Select 5 features, you can adjust this number\n",
    "\n",
    "# Fit RFE to your data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6320ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_selected and X_test_selected: (18414, 5) (12277, 5)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train is your original training DataFrame\n",
    "# selected_features contains the names of the features selected by RFE\n",
    "\n",
    "# Filter the training DataFrame to include only the selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Now X_train_selected contains only the selected features\n",
    "print(\"Shape of X_train_selected and X_test_selected:\", X_train_selected.shape, X_test_selected.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8e0dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3739           0.0122            3.10m\n",
      "         2           1.3643           0.0095            2.95m\n",
      "         3           1.3548           0.0093            2.90m\n",
      "         4           1.3442           0.0105            2.87m\n",
      "         5           1.3320           0.0120            2.92m\n",
      "         6           1.3202           0.0114            2.93m\n",
      "         7           1.3086           0.0114            2.94m\n",
      "         8           1.2983           0.0105            3.02m\n",
      "         9           1.2885           0.0097            3.02m\n",
      "        10           1.2776           0.0110            3.00m\n",
      "        20           1.1891           0.0082            3.02m\n",
      "        30           1.1049           0.0080            3.03m\n",
      "        40           1.0345           0.0070            3.64m\n",
      "        50           0.9672           0.0060            3.73m\n",
      "        60           0.9109           0.0048            3.84m\n",
      "        70           0.8601           0.0052            3.82m\n",
      "        80           0.8108           0.0050            3.82m\n",
      "        90           0.7683           0.0027            3.94m\n",
      "       100           0.7360           0.0037            4.00m\n",
      "       200           0.4495           0.0016            4.02m\n",
      "       300           0.3192           0.0012            3.88m\n",
      "       400           0.2327           0.0010            3.83m\n",
      "       500           0.1727           0.0006            3.87m\n",
      "       600           0.1308           0.0007            3.77m\n",
      "       700           0.1003           0.0002            3.83m\n",
      "       800           0.0750           0.0002            3.71m\n",
      "       900           0.0592           0.0002            3.70m\n",
      "      1000           0.0466           0.0000            3.58m\n",
      "      2000           0.0071           0.0000            2.84m\n",
      "      3000           0.0018           0.0000            2.13m\n",
      "      4000           0.0004          -0.0000            1.41m\n",
      "      5000           0.0006          -0.0000           42.16s\n",
      "      6000           0.0001          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3745           0.0115            7.10m\n",
      "         2           1.3636           0.0109            7.05m\n",
      "         3           1.3524           0.0107            7.11m\n",
      "         4           1.3431           0.0090            7.16m\n",
      "         5           1.3347           0.0088            7.14m\n",
      "         6           1.3231           0.0111            7.22m\n",
      "         7           1.3130           0.0099            7.27m\n",
      "         8           1.3023           0.0107            7.31m\n",
      "         9           1.2918           0.0108            7.38m\n",
      "        10           1.2806           0.0102            7.37m\n",
      "        20           1.1898           0.0074            5.61m\n",
      "        30           1.1103           0.0080            4.78m\n",
      "        40           1.0377           0.0074            4.42m\n",
      "        50           0.9725           0.0069            4.16m\n",
      "        60           0.9159           0.0048            4.17m\n",
      "        70           0.8709           0.0042            4.66m\n",
      "        80           0.8244           0.0041            4.99m\n",
      "        90           0.7757           0.0045            4.76m\n",
      "       100           0.7441           0.0022            4.59m\n",
      "       200           0.4630           0.0012            4.28m\n",
      "       300           0.3166           0.0019            4.33m\n",
      "       400           0.2341           0.0014            4.13m\n",
      "       500           0.1749           0.0003            4.14m\n",
      "       600           0.1346           0.0008            3.98m\n",
      "       700           0.1002           0.0004            4.27m\n",
      "       800           0.0781           0.0002            4.48m\n",
      "       900           0.0613           0.0002            4.61m\n",
      "      1000           0.0490           0.0001            4.69m\n",
      "      2000           0.0081           0.0000            4.35m\n",
      "      3000           0.0026           0.0000            2.93m\n",
      "      4000           0.0014          -0.0000            1.81m\n",
      "      5000           0.0011          -0.0000           51.59s\n",
      "      6000           0.0010          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3740           0.0119            3.60m\n",
      "         2           1.3625           0.0112            3.20m\n",
      "         3           1.3511           0.0117            3.03m\n",
      "         4           1.3403           0.0105            3.02m\n",
      "         5           1.3284           0.0114            3.20m\n",
      "         6           1.3173           0.0112            3.11m\n",
      "         7           1.3068           0.0104            3.21m\n",
      "         8           1.2961           0.0110            3.17m\n",
      "         9           1.2861           0.0101            3.13m\n",
      "        10           1.2750           0.0101            3.11m\n",
      "        20           1.1830           0.0090            3.96m\n",
      "        30           1.1005           0.0079            5.14m\n",
      "        40           1.0298           0.0066            5.23m\n",
      "        50           0.9696           0.0045            4.83m\n",
      "        60           0.9109           0.0056            4.53m\n",
      "        70           0.8582           0.0042            4.31m\n",
      "        80           0.8141           0.0043            4.14m\n",
      "        90           0.7703           0.0041            4.39m\n",
      "       100           0.7319           0.0041            4.69m\n",
      "       200           0.4667           0.0018            4.30m\n",
      "       300           0.3232           0.0014            4.19m\n",
      "       400           0.2350           0.0004            4.19m\n",
      "       500           0.1780           0.0004            4.02m\n",
      "       600           0.1349           0.0002            4.00m\n",
      "       700           0.1004           0.0002            3.86m\n",
      "       800           0.0765           0.0004            3.84m\n",
      "       900           0.0608           0.0002            3.72m\n",
      "      1000           0.0491           0.0000            3.63m\n",
      "      2000           0.0082           0.0000            2.93m\n",
      "      3000           0.0025          -0.0000            2.15m\n",
      "      4000           0.0014          -0.0000            1.42m\n",
      "      5000           0.0007          -0.0000           42.34s\n",
      "      6000           0.0010          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3736           0.0124            7.20m\n",
      "         2           1.3627           0.0110            7.20m\n",
      "         3           1.3519           0.0105            7.76m\n",
      "         4           1.3402           0.0112            7.63m\n",
      "         5           1.3289           0.0116            7.56m\n",
      "         6           1.3179           0.0106            7.42m\n",
      "         7           1.3070           0.0107            6.94m\n",
      "         8           1.2965           0.0103            6.44m\n",
      "         9           1.2861           0.0100            6.04m\n",
      "        10           1.2756           0.0100            5.73m\n",
      "        20           1.1844           0.0097            4.38m\n",
      "        30           1.1064           0.0085            3.93m\n",
      "        40           1.0333           0.0067            3.70m\n",
      "        50           0.9657           0.0073            3.57m\n",
      "        60           0.9024           0.0052            4.04m\n",
      "        70           0.8470           0.0049            4.55m\n",
      "        80           0.7968           0.0050            4.46m\n",
      "        90           0.7537           0.0037            4.30m\n",
      "       100           0.7159           0.0039            4.17m\n",
      "       200           0.4410           0.0024            4.24m\n",
      "       300           0.3084           0.0003            4.17m\n",
      "       400           0.2294           0.0003            3.98m\n",
      "       500           0.1715           0.0003            4.03m\n",
      "       600           0.1261           0.0004            3.88m\n",
      "       700           0.0942           0.0005            3.93m\n",
      "       800           0.0728           0.0001            3.81m\n",
      "       900           0.0568           0.0000            3.78m\n",
      "      1000           0.0453           0.0001            3.66m\n",
      "      2000           0.0077           0.0000            2.87m\n",
      "      3000           0.0024           0.0000            2.17m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4000           0.0014          -0.0000            1.43m\n",
      "      5000           0.0007          -0.0000           42.22s\n",
      "      6000           0.0006          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3746           0.0118            2.90m\n",
      "         2           1.3632           0.0114            2.85m\n",
      "         3           1.3511           0.0119            2.83m\n",
      "         4           1.3403           0.0106            2.82m\n",
      "         5           1.3300           0.0102            3.03m\n",
      "         6           1.3197           0.0099            3.01m\n",
      "         7           1.3090           0.0105            2.99m\n",
      "         8           1.2971           0.0117            3.08m\n",
      "         9           1.2869           0.0106            3.08m\n",
      "        10           1.2755           0.0111            3.07m\n",
      "        20           1.1774           0.0088            3.05m\n",
      "        30           1.1017           0.0082            3.03m\n",
      "        40           1.0288           0.0070            3.03m\n",
      "        50           0.9641           0.0070            3.84m\n",
      "        60           0.9112           0.0052            4.46m\n",
      "        70           0.8610           0.0044            4.40m\n",
      "        80           0.8119           0.0044            4.23m\n",
      "        90           0.7704           0.0043            4.09m\n",
      "       100           0.7253           0.0049            3.98m\n",
      "       200           0.4332           0.0023            4.26m\n",
      "       300           0.3036           0.0007            4.10m\n",
      "       400           0.2234           0.0003            4.03m\n",
      "       500           0.1606           0.0002            3.98m\n",
      "       600           0.1210           0.0004            3.84m\n",
      "       700           0.0921           0.0003            3.87m\n",
      "       800           0.0714           0.0002            3.77m\n",
      "       900           0.0558           0.0002            3.75m\n",
      "      1000           0.0450           0.0001            3.63m\n",
      "      2000           0.0078           0.0000            2.93m\n",
      "      3000           0.0024          -0.0000            2.18m\n",
      "      4000           0.0014          -0.0000            1.44m\n",
      "      5000           0.0007          -0.0000           42.67s\n",
      "      6000           0.0006          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3743           0.0115            3.40m\n",
      "         2           1.3625           0.0117            3.15m\n",
      "         3           1.3507           0.0113            3.03m\n",
      "         4           1.3397           0.0111            2.97m\n",
      "         5           1.3294           0.0100            2.98m\n",
      "         6           1.3196           0.0101            2.98m\n",
      "         7           1.3084           0.0106            2.97m\n",
      "         8           1.2971           0.0114            3.15m\n",
      "         9           1.2857           0.0109            3.16m\n",
      "        10           1.2762           0.0096            3.14m\n",
      "        20           1.1799           0.0081            3.08m\n",
      "        30           1.0986           0.0069            3.39m\n",
      "        40           1.0240           0.0073            4.42m\n",
      "        50           0.9595           0.0072            4.97m\n",
      "        60           0.8997           0.0057            4.64m\n",
      "        70           0.8468           0.0056            4.40m\n",
      "        80           0.7983           0.0048            4.22m\n",
      "        90           0.7608           0.0036            4.08m\n",
      "       100           0.7233           0.0024            3.96m\n",
      "       200           0.4534           0.0020            4.11m\n",
      "       300           0.3192           0.0011            3.97m\n",
      "       400           0.2346           0.0007            3.97m\n",
      "       500           0.1732           0.0005            3.95m\n",
      "       600           0.1333           0.0003            3.84m\n",
      "       700           0.1017           0.0006            3.81m\n",
      "       800           0.0789           0.0003            3.69m\n",
      "       900           0.0621           0.0001            3.68m\n",
      "      1000           0.0492           0.0001            3.58m\n",
      "      2000           0.0078           0.0000            2.86m\n",
      "      3000           0.0026           0.0000            2.16m\n",
      "      4000           0.0014          -0.0000            1.44m\n",
      "      5000           0.0007          -0.0000           42.59s\n",
      "      6000           0.0010          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3740           0.0119            7.30m\n",
      "         2           1.3622           0.0117            7.25m\n",
      "         3           1.3499           0.0119            7.29m\n",
      "         4           1.3390           0.0108            7.35m\n",
      "         5           1.3296           0.0091            7.29m\n",
      "         6           1.3213           0.0086            7.29m\n",
      "         7           1.3099           0.0109            7.33m\n",
      "         8           1.2995           0.0103            7.33m\n",
      "         9           1.2910           0.0078            7.31m\n",
      "        10           1.2813           0.0095            7.33m\n",
      "        20           1.1895           0.0088            7.38m\n",
      "        30           1.1062           0.0074            5.95m\n",
      "        40           1.0373           0.0076            5.21m\n",
      "        50           0.9752           0.0052            4.82m\n",
      "        60           0.9226           0.0040            4.52m\n",
      "        70           0.8694           0.0057            4.50m\n",
      "        80           0.8240           0.0054            4.87m\n",
      "        90           0.7802           0.0038            5.02m\n",
      "       100           0.7407           0.0042            4.89m\n",
      "       200           0.4576           0.0015            4.42m\n",
      "       300           0.3238           0.0004            4.44m\n",
      "       400           0.2364           0.0005            4.19m\n",
      "       500           0.1802           0.0006            4.19m\n",
      "       600           0.1392           0.0002            4.01m\n",
      "       700           0.1062           0.0005            3.97m\n",
      "       800           0.0792           0.0004            3.87m\n",
      "       900           0.0620           0.0001            3.76m\n",
      "      1000           0.0499           0.0000            3.70m\n",
      "      2000           0.0078           0.0000            2.90m\n",
      "      3000           0.0026           0.0000            2.16m\n",
      "      4000           0.0014          -0.0000            1.43m\n",
      "      5000           0.0011          -0.0000           42.37s\n",
      "      6000           0.0002          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3753           0.0108           25.36m\n",
      "         2           1.3639           0.0115           20.00m\n",
      "         3           1.3526           0.0108           19.03m\n",
      "         4           1.3408           0.0120           18.90m\n",
      "         5           1.3286           0.0119           18.00m\n",
      "         6           1.3176           0.0108           17.54m\n",
      "         7           1.3065           0.0110           16.59m\n",
      "         8           1.2955           0.0109           15.80m\n",
      "         9           1.2851           0.0103           15.14m\n",
      "        10           1.2743           0.0103           14.55m\n",
      "        20           1.1807           0.0094           12.34m\n",
      "        30           1.0990           0.0080           12.53m\n",
      "        40           1.0257           0.0066           11.71m\n",
      "        50           0.9632           0.0063           11.99m\n",
      "        60           0.9052           0.0051           11.45m\n",
      "        70           0.8550           0.0052           10.71m\n",
      "        80           0.8083           0.0039           10.17m\n",
      "        90           0.7674           0.0039            9.82m\n",
      "       100           0.7301           0.0033            9.24m\n",
      "       200           0.4702           0.0010            6.45m\n",
      "       300           0.3209           0.0011            5.79m\n",
      "       400           0.2334           0.0010            5.50m\n",
      "       500           0.1771           0.0008            5.07m\n",
      "       600           0.1308           0.0004            4.97m\n",
      "       700           0.1001           0.0003            4.70m\n",
      "       800           0.0761           0.0001            4.59m\n",
      "       900           0.0596           0.0001            4.39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1000           0.0467           0.0000            4.29m\n",
      "      2000           0.0077           0.0000            3.43m\n",
      "      3000           0.0025           0.0000            2.54m\n",
      "      4000           0.0014           0.0000            1.71m\n",
      "      5000           0.0011          -0.0000           50.09s\n",
      "      6000           0.0010          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3744           0.0116            3.71m\n",
      "         2           1.3635           0.0107            3.36m\n",
      "         3           1.3511           0.0123            3.22m\n",
      "         4           1.3400           0.0109            3.14m\n",
      "         5           1.3293           0.0109            3.26m\n",
      "         6           1.3191           0.0100            3.27m\n",
      "         7           1.3082           0.0104            3.30m\n",
      "         8           1.2974           0.0111            3.31m\n",
      "         9           1.2861           0.0111            3.32m\n",
      "        10           1.2761           0.0095            3.31m\n",
      "        20           1.1815           0.0095            3.43m\n",
      "        30           1.0985           0.0083            3.58m\n",
      "        40           1.0292           0.0070            4.33m\n",
      "        50           0.9659           0.0064            5.00m\n",
      "        60           0.9085           0.0052            4.95m\n",
      "        70           0.8549           0.0034            4.75m\n",
      "        80           0.8066           0.0050            4.57m\n",
      "        90           0.7579           0.0044            4.47m\n",
      "       100           0.7202           0.0032            4.48m\n",
      "       200           0.4568           0.0019            4.70m\n",
      "       300           0.3149           0.0008            4.76m\n",
      "       400           0.2259           0.0011            4.52m\n",
      "       500           0.1716           0.0003            4.51m\n",
      "       600           0.1277           0.0001            4.34m\n",
      "       700           0.0996           0.0005            4.29m\n",
      "       800           0.0755           0.0004            4.17m\n",
      "       900           0.0605           0.0002            4.09m\n",
      "      1000           0.0479           0.0001            3.99m\n",
      "      2000           0.0078           0.0000            3.05m\n",
      "      3000           0.0021           0.0000            2.27m\n",
      "      4000           0.0010           0.0000            1.48m\n",
      "      5000           0.0006          -0.0000           43.63s\n",
      "      6000           0.0005          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3746           0.0116            2.79m\n",
      "         2           1.3624           0.0118            2.85m\n",
      "         3           1.3532           0.0088            2.83m\n",
      "         4           1.3425           0.0109            2.89m\n",
      "         5           1.3313           0.0112            2.91m\n",
      "         6           1.3202           0.0108            2.91m\n",
      "         7           1.3090           0.0109            3.01m\n",
      "         8           1.3012           0.0082            3.02m\n",
      "         9           1.2895           0.0113            3.51m\n",
      "        10           1.2787           0.0110            3.92m\n",
      "        20           1.1901           0.0094            5.78m\n",
      "        30           1.1130           0.0087            5.99m\n",
      "        40           1.0473           0.0063            5.31m\n",
      "        50           0.9817           0.0071            4.86m\n",
      "        60           0.9235           0.0061            4.55m\n",
      "        70           0.8772           0.0044            4.32m\n",
      "        80           0.8284           0.0050            4.48m\n",
      "        90           0.7885           0.0045            4.89m\n",
      "       100           0.7458           0.0044            4.91m\n",
      "       200           0.4563           0.0025            4.35m\n",
      "       300           0.3008           0.0017            4.48m\n",
      "       400           0.2156           0.0003            4.29m\n",
      "       500           0.1636           0.0007            4.25m\n",
      "       600           0.1237           0.0007            4.08m\n",
      "       700           0.0952           0.0004            3.95m\n",
      "       800           0.0728           0.0000            3.91m\n",
      "       900           0.0575           0.0002            3.77m\n",
      "      1000           0.0451           0.0000            3.74m\n",
      "      2000           0.0078           0.0000            2.95m\n",
      "      3000           0.0024           0.0000            2.19m\n",
      "      4000           0.0014          -0.0000            1.45m\n",
      "      5000           0.0011          -0.0000           42.74s\n",
      "      6000           0.0010          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3744           0.0117            5.50m\n",
      "         2           1.3620           0.0123            4.65m\n",
      "         3           1.3509           0.0109            4.50m\n",
      "         4           1.3387           0.0118            4.40m\n",
      "         5           1.3278           0.0110            4.16m\n",
      "         6           1.3192           0.0085            4.11m\n",
      "         7           1.3075           0.0113            4.00m\n",
      "         8           1.2970           0.0106            3.91m\n",
      "         9           1.2871           0.0101            3.84m\n",
      "        10           1.2762           0.0099            3.78m\n",
      "        20           1.1850           0.0083            5.61m\n",
      "        30           1.1037           0.0081            6.51m\n",
      "        40           1.0309           0.0072            5.87m\n",
      "        50           0.9662           0.0067            5.36m\n",
      "        60           0.9102           0.0062            5.04m\n",
      "        70           0.8579           0.0054            4.81m\n",
      "        80           0.8089           0.0054            4.98m\n",
      "        90           0.7715           0.0037            5.34m\n",
      "       100           0.7301           0.0040            5.22m\n",
      "       200           0.4506           0.0021            4.91m\n",
      "       300           0.3186           0.0008            4.76m\n",
      "       400           0.2346           0.0009            4.68m\n",
      "       500           0.1781           0.0006            4.49m\n",
      "       600           0.1358           0.0001            4.48m\n",
      "       700           0.1036           0.0001            4.31m\n",
      "       800           0.0789           0.0003            4.26m\n",
      "       900           0.0615           0.0001            4.11m\n",
      "      1000           0.0482           0.0001            4.02m\n",
      "      2000           0.0083           0.0000            3.16m\n",
      "      3000           0.0026           0.0000            2.39m\n",
      "      4000           0.0014           0.0000            1.59m\n",
      "      5000           0.0010          -0.0000           47.19s\n",
      "      6000           0.0009          -0.0000            0.00s\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 6000, 'subsample': 0.8, 'verbose': 1}\n",
      "Test Accuracy: 0.995031359452635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_gradient_boosting_model.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Split Data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Step 2: Upsample Training Data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "# Step 3: Hyperparameter Tuning with Gradient Boosting and k-fold Cross Validation\n",
    "param_grid = {\n",
    "    'n_estimators': [6000],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [8],\n",
    "    'subsample': [0.8],\n",
    "    'verbose': [1],\n",
    "    \n",
    "}\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(gb_classifier, param_grid, cv=kf, scoring='accuracy')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "best_gb_classifier = grid_search.best_estimator_\n",
    "y_pred_test = best_gb_classifier.predict(X_test_selected)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Save the best model\n",
    "model_filename = 'best_gradient_boosting_model.pkl'\n",
    "joblib.dump(best_gb_classifier, model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05cc865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Random Forest): {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200, 'verbose': 1}\n",
      "Test Accuracy (Random Forest): 0.9953571719475441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_rf_classifier_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Step 4: Hyperparameter Tuning with Random Forest and k-fold Cross Validation\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'verbose': [1],\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=kf, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "best_rf_classifier = grid_search_rf.best_estimator_\n",
    "y_pred_test_rf = best_rf_classifier.predict(X_test_selected)\n",
    "accuracy_test_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "\n",
    "print(\"Best Hyperparameters (Random Forest):\", best_params_rf)\n",
    "print(\"Test Accuracy (Random Forest):\", accuracy_test_rf)\n",
    "\n",
    "\n",
    "# Step 1: Save the best model\n",
    "model_filename = 'best_rf_classifier_model.pkl'\n",
    "joblib.dump(best_rf_classifier, model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72f53364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraj4\\AppData\\Local\\Temp/ipykernel_10424/2884953122.py:37: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  mlp_classifier = KerasClassifier(build_fn=create_mlp_model, verbose=0)\n",
      "C:\\Users\\rraj4\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (MLP): {'units': 256, 'optimizer': 'adam', 'epochs': 40, 'batch_size': 32, 'activation': 'relu'}\n",
      "Test Accuracy (MLP): 0.8985908609595178\n",
      "INFO:tensorflow:Assets written to: ram://303a8052-7e8f-4871-9093-8de02e2d06ef/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_mlp_classifier_model.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.wrappers.scikit_learn import KerasClassifier  # Import KerasClassifier\n",
    "import joblib\n",
    "\n",
    "# Step 2: Upsample Training Data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "# Step 4: Hyperparameter Tuning with MLP and k-fold Cross Validation\n",
    "param_dist_mlp = {\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [40],\n",
    "    'optimizer': ['adam'],\n",
    "    'activation': ['relu'],\n",
    "    'units': [256],\n",
    "}\n",
    "\n",
    "# Define MLP model function with flexible hyperparameters\n",
    "def create_mlp_model(optimizer='adam', activation='relu', units=64):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units, activation=activation, input_dim=X_train_resampled.shape[1]))\n",
    "    model.add(Dense(units=units // 2, activation=activation))\n",
    "    model.add(Dense(units=units // 4, activation=activation))  # Additional layer 1\n",
    "    model.add(Dense(units=units // 8, activation=activation))  # Additional layer 2\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "mlp_classifier = KerasClassifier(build_fn=create_mlp_model, verbose=0)\n",
    "kf = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "random_search_mlp = RandomizedSearchCV(estimator=mlp_classifier, \n",
    "                                        param_distributions=param_dist_mlp, \n",
    "                                        n_iter=10,  # Number of random parameter combinations to try\n",
    "                                        cv=kf, \n",
    "                                        scoring='accuracy',\n",
    "                                        random_state=42)\n",
    "random_search_mlp.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params_mlp = random_search_mlp.best_params_\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "best_mlp_classifier = random_search_mlp.best_estimator_\n",
    "y_pred_test_mlp = best_mlp_classifier.predict(X_test_selected)\n",
    "accuracy_test_mlp = accuracy_score(y_test, y_pred_test_mlp)\n",
    "\n",
    "print(\"Best Hyperparameters (MLP):\", best_params_mlp)\n",
    "print(\"Test Accuracy (MLP):\", accuracy_test_mlp)\n",
    "\n",
    "\n",
    "# Step 1: Save the best model\n",
    "model_filename = 'best_mlp_classifier_model.pkl'\n",
    "joblib.dump(best_mlp_classifier, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75765351",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.trackable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17860/3787615293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m  \u001b[1;31m# Import KerasClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_tf_keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\_tf_keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tf_keras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\activations\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\activations\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0melu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexponential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\activations\\activations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_tensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_tensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\common\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutocastScope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_autocast_scope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mBOOL_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"bool\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\common\\variables.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateless_scope\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0min_stateless_scope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaming\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menable_interactive_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_interactive_logging_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_visualization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_visualization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\model_visualization.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tree.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Register backend-specific node classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tensorflow\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_structures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mListWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     optree.register_pytree_node(\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.trackable'"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier  # Import KerasClassifier\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Step 2: Upsample Training Data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "# Assuming X_train_resampled is a DataFrame, convert it to a NumPy array first\n",
    "X_train_resampled_array = X_train_resampled.values\n",
    "\n",
    "# Reshape the NumPy array\n",
    "X_train_reshaped = X_train_resampled_array.reshape((X_train_resampled_array.shape[0], X_train_resampled_array.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model function\n",
    "def create_lstm_model(units=64, optimizer='adam', activation='relu', batch_size=32, epochs=20):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, activation=activation, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(units=units // 2, activation=activation))\n",
    "    model.add(Dense(units=units // 4, activation=activation))  # Additional layer 1\n",
    "    model.add(Dense(units=units // 8, activation=activation))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define parameters for grid search\n",
    "param_dist_lstm = {\n",
    "    'units': [128],\n",
    "    'optimizer': ['adam'],\n",
    "    'activation': ['relu'],\n",
    "    'batch_size': [64],\n",
    "    'epochs': [40]\n",
    "}\n",
    "\n",
    "# Initialize KerasClassifier with LSTM model function\n",
    "lstm_classifier = KerasClassifier(build_fn=create_lstm_model, verbose=0)\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "kf = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "random_search_lstm = RandomizedSearchCV(estimator=lstm_classifier, \n",
    "                                        param_distributions=param_dist_lstm, \n",
    "                                        cv=kf, \n",
    "                                        scoring='accuracy',\n",
    "                                        random_state=42)\n",
    "# Fit the GridSearchCV instance\n",
    "random_search_lstm.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best hyperparameters for LSTM\n",
    "best_params_lstm = random_search_lstm.best_params_\n",
    "\n",
    "# Model Evaluation\n",
    "best_lstm_classifier = random_search_lstm.best_estimator_\n",
    "y_pred_test_lstm = best_lstm_classifier.predict(X_test_selected)\n",
    "accuracy_test_lstm = accuracy_score(y_test, y_pred_test_lstm)\n",
    "\n",
    "print(\"Best Hyperparameters (LSTM):\", best_params_lstm)\n",
    "print(\"Test Accuracy (LSTM):\", accuracy_test_lstm)\n",
    "\n",
    "# Save the best LSTM model\n",
    "model_filename_lstm = 'best_lstm_classifier_model.pkl'\n",
    "joblib.dump(best_lstm_classifier, model_filename_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02f832ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26186, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9da29132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Downloading tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl (127 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Collecting h5py>=3.10.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\rraj4\\\\anaconda3\\\\Lib\\\\site-packages\\\\google\\\\~rotobuf\\\\internal\\\\_api_implementation.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.25.0)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.12.1)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.46.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.3-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (14.0.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: namex in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: rich in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: optree in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.10)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.2)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.62.1-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rraj4\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Installing collected packages: numpy, tensorboard-data-server, protobuf, ml-dtypes, h5py, grpcio, tensorboard, flatbuffers, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11074301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikeras\n",
      "Version: 0.13.0\n",
      "Summary: Scikit-Learn API wrapper for Keras.\n",
      "Home-page: https://github.com/adriangb/scikeras\n",
      "Author: Adrian Garcia Badaracco\n",
      "Author-email: 1755071+adriangb@users.noreply.github.com\n",
      "License: MIT\n",
      "Location: c:\\users\\rraj4\\appdata\\roaming\\python\\python39\\site-packages\n",
      "Requires: keras, scikit-learn\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rraj4\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip show scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc76ce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- --------------------\n",
      "absl-py                            1.0.0\n",
      "alabaster                          0.7.12\n",
      "anaconda-client                    1.9.0\n",
      "anaconda-navigator                 2.1.1\n",
      "anaconda-project                   0.10.1\n",
      "annotated-types                    0.6.0\n",
      "anyio                              4.2.0\n",
      "appdirs                            1.4.4\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "arrow                              0.13.1\n",
      "article                            0.1.1\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.6.6\n",
      "astropy                            4.3.1\n",
      "astunparse                         1.6.3\n",
      "async-generator                    1.10\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              21.2.0\n",
      "audioread                          3.0.0\n",
      "autopep8                           1.5.7\n",
      "Babel                              2.9.1\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.12.2\n",
      "binaryornot                        0.4.4\n",
      "bitarray                           2.3.0\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             4.0.0\n",
      "bokeh                              2.4.1\n",
      "boto                               2.49.0\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "bs4                                0.0.1\n",
      "cached-property                    1.5.2\n",
      "cachetools                         5.0.0\n",
      "certifi                            2021.10.8\n",
      "cffi                               1.14.6\n",
      "chardet                            3.0.4\n",
      "charset-normalizer                 2.0.4\n",
      "click                              8.0.3\n",
      "cloudpickle                        2.0.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.4\n",
      "colorlover                         0.3.0\n",
      "comtypes                           1.1.10\n",
      "conda                              4.10.3\n",
      "conda-build                        3.21.6\n",
      "conda-content-trust                0+unknown\n",
      "conda-pack                         0.6.0\n",
      "conda-package-handling             1.7.3\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "contextlib2                        0.6.0.post1\n",
      "cookiecutter                       1.7.2\n",
      "cryptography                       3.4.8\n",
      "cssselect                          1.2.0\n",
      "cufflinks                          0.17.3\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.24\n",
      "cytoolz                            0.11.0\n",
      "daal4py                            2021.3.0\n",
      "dask                               2021.10.0\n",
      "debugpy                            1.4.1\n",
      "decorator                          5.1.0\n",
      "defusedxml                         0.7.1\n",
      "diff-match-patch                   20200713\n",
      "distributed                        2021.10.0\n",
      "distro                             1.9.0\n",
      "docutils                           0.17.1\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.1.0\n",
      "exceptiongroup                     1.2.0\n",
      "fastcache                          1.1.0\n",
      "feedfinder2                        0.0.4\n",
      "feedparser                         6.0.10\n",
      "filelock                           3.3.1\n",
      "flake8                             3.9.2\n",
      "Flask                              1.1.2\n",
      "flatbuffers                        2.0\n",
      "fonttools                          4.25.0\n",
      "frozendict                         2.3.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rraj4\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rraj4\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rraj4\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rraj4\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsspec                             2021.10.1\n",
      "future                             0.18.2\n",
      "gast                               0.5.3\n",
      "gevent                             21.8.0\n",
      "glob2                              0.7\n",
      "google-auth                        2.6.6\n",
      "google-auth-oauthlib               0.4.6\n",
      "google-pasta                       0.2.0\n",
      "google-trans-new                   1.1.9\n",
      "googletrans                        4.0.0rc1\n",
      "greenlet                           1.1.1\n",
      "grpcio                             1.46.0\n",
      "h11                                0.14.0\n",
      "h2                                 3.2.0\n",
      "h5py                               3.2.1\n",
      "HeapDict                           1.0.1\n",
      "hpack                              3.0.0\n",
      "hstspreload                        2021.12.1\n",
      "html5lib                           1.1\n",
      "httpcore                           1.0.2\n",
      "httpx                              0.26.0\n",
      "hyperframe                         5.2.0\n",
      "idna                               2.10\n",
      "imagecodecs                        2021.8.26\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "imbalanced-learn                   0.12.0\n",
      "imblearn                           0.0\n",
      "importlib-metadata                 4.8.1\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          6.4.1\n",
      "ipython                            7.29.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.6.5\n",
      "isort                              5.9.3\n",
      "itsdangerous                       2.0.1\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.18.0\n",
      "jieba3k                            0.35.1\n",
      "Jinja2                             2.11.3\n",
      "jinja2-time                        0.2.0\n",
      "joblib                             1.2.0\n",
      "json5                              0.9.6\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.12\n",
      "jupyter-console                    6.4.0\n",
      "jupyter-core                       4.8.1\n",
      "jupyter-server                     1.4.1\n",
      "jupyterlab                         3.2.1\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.8.2\n",
      "jupyterlab-widgets                 1.0.0\n",
      "keras                              3.2.1\n",
      "Keras-Preprocessing                1.1.2\n",
      "keras-tuner                        1.3.5\n",
      "keyring                            23.1.0\n",
      "kiwisolver                         1.3.1\n",
      "kt-legacy                          1.0.5\n",
      "lazy_loader                        0.2\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "libclang                           14.0.1\n",
      "librosa                            0.10.0.post2\n",
      "llvmlite                           0.37.0\n",
      "locket                             0.2.1\n",
      "lxml                               4.9.3\n",
      "Markdown                           3.3.7\n",
      "markdown-it-py                     3.0.0\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.4.3\n",
      "matplotlib-inline                  0.1.2\n",
      "mccabe                             0.6.1\n",
      "mdurl                              0.1.2\n",
      "menuinst                           1.4.18\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.1\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "ml-dtypes                          0.4.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.10.0\n",
      "mpmath                             1.2.1\n",
      "msgpack                            1.0.2\n",
      "multipledispatch                   0.6.0\n",
      "multitasking                       0.0.11\n",
      "munkres                            1.1.4\n",
      "mypy-extensions                    0.4.3\n",
      "namex                              0.0.7\n",
      "navigator-updater                  0.2.1\n",
      "nbclassic                          0.2.6\n",
      "nbclient                           0.5.3\n",
      "nbconvert                          6.1.0\n",
      "nbformat                           5.1.3\n",
      "nest-asyncio                       1.5.1\n",
      "networkx                           2.6.3\n",
      "newspaper3k                        0.2.8\n",
      "nltk                               3.6.5\n",
      "nose                               1.3.7\n",
      "notebook                           6.4.5\n",
      "numba                              0.54.1\n",
      "numexpr                            2.7.3\n",
      "numpy                              1.26.4\n",
      "numpydoc                           1.1.0\n",
      "oauthlib                           3.2.0\n",
      "olefile                            0.46\n",
      "openai                             1.6.1\n",
      "openpyxl                           3.0.9\n",
      "opt-einsum                         3.3.0\n",
      "optree                             0.11.0\n",
      "packaging                          21.0\n",
      "pandas                             1.3.4\n",
      "pandas-datareader                  0.10.0\n",
      "pandocfilters                      1.4.3\n",
      "paramiko                           2.7.2\n",
      "parso                              0.8.2\n",
      "partd                              1.2.0\n",
      "path                               16.0.0\n",
      "pathlib2                           2.3.6\n",
      "pathspec                           0.7.0\n",
      "patsy                              0.5.2\n",
      "peewee                             3.17.0\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.4.0\n",
      "pip                                21.2.4\n",
      "pkginfo                            1.7.1\n",
      "plotly                             5.10.0\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "pooch                              1.6.0\n",
      "poyo                               0.5.0\n",
      "prettytable                        3.3.0\n",
      "prometheus-client                  0.11.0\n",
      "prompt-toolkit                     3.0.20\n",
      "protobuf                           4.25.3\n",
      "psutil                             5.8.0\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.10.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pycodestyle                        2.7.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pycurl                             7.44.1\n",
      "pydantic                           2.5.3\n",
      "pydantic_core                      2.14.6\n",
      "pydocstyle                         6.1.1\n",
      "pydotplus                          2.0.2\n",
      "pyerfa                             2.0.0\n",
      "pyflakes                           2.3.1\n",
      "Pygments                           2.17.2\n",
      "PyJWT                              2.1.0\n",
      "pylint                             2.9.6\n",
      "pyls-spyder                        0.4.0\n",
      "PyMuPDF                            1.23.8\n",
      "PyMuPDFb                           1.23.7\n",
      "PyNaCl                             1.4.0\n",
      "pyodbc                             4.0.0-unsupported\n",
      "pyOpenSSL                          21.0.0\n",
      "pyparsing                          3.0.4\n",
      "pyreadline                         2.1\n",
      "pyrsistent                         0.18.0\n",
      "PySocks                            1.7.1\n",
      "pytest                             6.2.4\n",
      "python-dateutil                    2.8.2\n",
      "python-lsp-black                   1.0.0\n",
      "python-lsp-jsonrpc                 1.0.0\n",
      "python-lsp-server                  1.2.4\n",
      "python-slugify                     5.0.2\n",
      "pytz                               2023.3.post1\n",
      "PyWavelets                         1.1.1\n",
      "pywin32                            228\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           0.5.7\n",
      "PyYAML                             6.0\n",
      "pyzmq                              22.2.1\n",
      "QDarkStyle                         3.0.2\n",
      "qstylizer                          0.1.10\n",
      "QtAwesome                          1.0.2\n",
      "qtconsole                          5.1.1\n",
      "QtPy                               1.10.0\n",
      "regex                              2021.8.3\n",
      "ReliefF                            0.1.2\n",
      "requests                           2.31.0\n",
      "requests-file                      1.5.1\n",
      "requests-oauthlib                  1.3.1\n",
      "resampy                            0.4.2\n",
      "rfc3986                            1.5.0\n",
      "rich                               13.7.1\n",
      "rope                               0.19.0\n",
      "rsa                                4.8\n",
      "Rtree                              0.9.7\n",
      "ruamel.yaml                        0.17.21\n",
      "ruamel.yaml.clib                   0.2.6\n",
      "ruamel-yaml-conda                  0.15.100\n",
      "scikeras                           0.13.0\n",
      "scikit-image                       0.18.3\n",
      "scikit-learn                       1.4.2\n",
      "scikit-learn-intelex               2021.20210714.120553\n",
      "scipy                              1.7.1\n",
      "seaborn                            0.11.2\n",
      "Send2Trash                         1.8.0\n",
      "setuptools                         58.0.4\n",
      "sgmllib3k                          1.0.0\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     3.7.0\n",
      "sip                                4.19.13\n",
      "six                                1.16.0\n",
      "sklearn                            0.0.post1\n",
      "skrebate                           0.62\n",
      "sniffio                            1.2.0\n",
      "snowballstemmer                    2.1.0\n",
      "sortedcollections                  2.1.0\n",
      "sortedcontainers                   2.4.0\n",
      "soundfile                          0.12.1\n",
      "soupsieve                          2.2.1\n",
      "soxr                               0.3.4\n",
      "Sphinx                             4.2.0\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             2.0.0\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.5\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             5.1.5\n",
      "spyder-kernels                     2.1.3\n",
      "SQLAlchemy                         1.4.22\n",
      "statsmodels                        0.12.2\n",
      "sympy                              1.9\n",
      "tables                             3.6.1\n",
      "TBB                                0.2\n",
      "tblib                              1.7.0\n",
      "tenacity                           8.0.1\n",
      "tensorboard                        2.8.0\n",
      "tensorboard-data-server            0.7.2\n",
      "tensorboard-plugin-wit             1.8.1\n",
      "tensorflow                         2.8.0\n",
      "tensorflow-io-gcs-filesystem       0.25.0\n",
      "termcolor                          1.1.0\n",
      "terminado                          0.9.4\n",
      "testpath                           0.5.0\n",
      "text-unidecode                     1.3\n",
      "textblob                           0.17.1\n",
      "textdistance                       4.2.1\n",
      "tf-estimator-nightly               2.8.0.dev2021122109\n",
      "threadpoolctl                      2.2.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2021.7.2\n",
      "tinycss                            0.4\n",
      "tinysegmenter                      0.3\n",
      "tldextract                         3.4.0\n",
      "toml                               0.10.2\n",
      "toolz                              0.11.1\n",
      "tornado                            6.1\n",
      "tqdm                               4.62.3\n",
      "traitlets                          5.1.0\n",
      "typed-ast                          1.4.3\n",
      "typing_extensions                  4.9.0\n",
      "ujson                              4.0.2\n",
      "unicodecsv                         0.14.1\n",
      "Unidecode                          1.2.0\n",
      "urllib3                            1.26.7\n",
      "watchdog                           2.1.3\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "Werkzeug                           2.0.2\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c481a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
